import streamlit as st
import pandas as pd
import re
from datetime import datetime
import base64
import io
import requests

# Configuration
st.set_page_config(
    page_title="Analyse BUMIDOM - R√©sultats Google", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üìä Analyse des R√©sultats Google BUMIDOM")
st.markdown("Extraction et analyse des informations depuis vos r√©sultats Google")

def parse_google_results():
    """Parse les r√©sultats Google structur√©s"""
    
    # Donn√©es structur√©es extraites du HTML fourni
    results_data = [
        {
            'title': 'JOURNAL OFFICIAL - Assembl√©e nationale - Archives',
            'url': 'https://archives.assemblee-nationale.fr/4/cri/1971-1972-ordinaire1/024.pdf',
            'date': '26 oct. 1971',
            'extract': 'Bumidom. Nous avons donc fait un effort tr√®s s√©rieux ‚Äî je crois qu\'il commence √† porter ses fruits ‚Äî pour l\'information, comme on l\'a ...',
            'year': 1971,
            'file_name': '024.pdf'
        },
        {
            'title': 'CONSTITUTION DU 4 OCTOBRE 1958 4\' L√©gislature',
            'url': 'https://archives.assemblee-nationale.fr/4/cri/1968-1969-ordinaire1/050.pdf',
            'date': '9 nov. 2025',
            'extract': 'Bumidom. D√®s mon arriv√©e au minist√®re, je me suis essentiellement pr√©occup√© des conditions d\'accueil et d\'adaptation des originaires des ...',
            'year': 1968,
            'file_name': '050.pdf'
        },
        {
            'title': 'Assembl√©e nationale - Archives',
            'url': 'https://archives.assemblee-nationale.fr/2/cri/1966-1967-ordinaire1/021.pdf',
            'date': '',
            'extract': 'le BUMIDOM qui, en 1965, a facilit√© l\'installation en m√©tropole. La r√©alisation effective de la parit√© globale se poursuivra de 7.000 personnes. en. 1967 . C ...',
            'year': 1966,
            'file_name': '021.pdf'
        },
        {
            'title': 'CONSTITUTION DU 4 OCTOBRE 1958 7\' L√©gislature',
            'url': 'https://archives.assemblee-nationale.fr/7/cri/1982-1983-ordinaire1/057.pdf',
            'date': '5 nov. 1982',
            'extract': 'Le Bumidom, tant d√©cri√© par vos amis, a √©t√©, dans la pratique, remplac√© par un succ√©dan√© ‚Äî l\'agence nationale pour l\'insertion et la ...',
            'year': 1982,
            'file_name': '057.pdf'
        },
        {
            'title': 'COMPTE RENDU INTEGRAL - Assembl√©e nationale - Archives',
            'url': 'https://archives.assemblee-nationale.fr/5/cri/1976-1977-ordinaire2/057.pdf',
            'date': '27 janv. 2025',
            'extract': 'des cr√©dits affect√©s au Bumidom pour les ann√©es 1976 et 1977;. 2¬∞ les raisons de la r√©duction des cr√©dits pour l\'ann√©e 1977 si tou- tefois ...',
            'year': 1976,
            'file_name': '057.pdf'
        },
        {
            'title': 'CONSTITUTION DU 4 OCTOBRE 1958 4¬∞ L√©gislature',
            'url': 'https://archives.assemblee-nationale.fr/4/cri/1970-1971-ordinaire1/060.pdf',
            'date': '16 nov. 1970',
            'extract': 'des d√©partements d\'outre-mer ‚Äî Bumidom ‚Äî dont l\'objectif est √† la fois de faciliter l\'immigration et d\'orienter les tra- vailleurs vers un ...',
            'year': 1970,
            'file_name': '060.pdf'
        },
        {
            'title': 'DE LA R√âPUBLIQUE FRAN√áAISE - Assembl√©e nationale - Archives',
            'url': 'https://archives.assemblee-nationale.fr/8/cri/1985-1986-extraordinaire1/015.pdf',
            'date': '11 juil. 1986',
            'extract': 'Bumidom . On cr√©e l \' A.N.T., Agence nationale pour l \' inser- tion et la promotion des travailleurs. Le slogan gouverne- mental √©tait ...',
            'year': 1985,
            'file_name': '015.pdf'
        },
        {
            'title': 'JOUR AL OFFICIEL - Assembl√©e nationale - Archives',
            'url': 'https://archives.assemblee-nationale.fr/4/cri/1971-1972-ordinaire1/067.pdf',
            'date': '5 nov. 2025',
            'extract': 'soci√©t√© d \'Etat ¬´ Bumidom ¬ª, qui prend √† sa charge les frais du voyage. En cons√©quence, il lui demande quelles mesures il compte prendre ...',
            'year': 1971,
            'file_name': '067.pdf'
        },
        {
            'title': 'CONSTITUTION DU 4 OCTOBRE 1958 4¬∞ L√©gislature',
            'url': 'https://archives.assemblee-nationale.fr/4/cri/1970-1971-ordinaire1/023.pdf',
            'date': '26 oct. 1970',
            'extract': 'Le Bumidom ne devrait pas √™tre trait√© comme un instrument de la ... t√©s d\'accueil et du Bumidom, c\'est-√†-dire du bureau des migrations.',
            'year': 1970,
            'file_name': '023.pdf'
        },
        {
            'title': 'JOUR: AL OFFICIEL - Assembl√©e nationale - Archives',
            'url': 'https://archives.assemblee-nationale.fr/4/cri/1970-1971-ordinaire2/007.pdf',
            'date': '7 mars 2025',
            'extract': 'nis√©e par le Bumidom, est loin d\'√™tre satisfaisante. Ses effets sont du reste annihil√©s par l\'entr√©e d\'une main-d\'oeuvre impor- tante dans ...',
            'year': 1970,
            'file_name': '007.pdf'
        }
    ]
    
    # Formater les r√©sultats
    formatted_results = []
    for i, result in enumerate(results_data):
        # Extraire le nom de fichier pour l'URL partielle
        url_parts = result['url'].split('/')
        url_part = '/'.join(url_parts[-4:]) if len(url_parts) >= 4 else result['url']
        
        # Identifier le type de document
        doc_type = "CRI"
        title_upper = result['title'].upper()
        if 'CONSTITUTION' in title_upper:
            doc_type = "Constitution"
        elif 'JOURNAL' in title_upper or 'JOUR' in title_upper:
            doc_type = "Journal Officiel"
        elif 'COMPTE RENDU' in title_upper:
            doc_type = "Compte Rendu"
        elif 'R√âPUBLIQUE' in title_upper:
            doc_type = "D√©bat parlementaire"
        
        # Extraire la l√©gislature
        legislature = ""
        if "4'" in result['title'] or "4¬∞" in result['title']:
            legislature = "4√®me"
        elif "7'" in result['title']:
            legislature = "7√®me"
        elif "2'" in result['title'] or "Assembl√©e nationale" in result['title']:
            legislature = "2√®me"
        elif "5'" in result['title']:
            legislature = "5√®me"
        elif "8'" in result['title']:
            legislature = "8√®me"
        
        # Extraire la p√©riode parlementaire de l'URL
        periode = ""
        if 'ordinaire1' in result['url']:
            periode = "Session ordinaire 1"
        elif 'ordinaire2' in result['url']:
            periode = "Session ordinaire 2"
        elif 'extraordinaire' in result['url']:
            periode = "Session extraordinaire"
        
        formatted_results.append({
            'id': i + 1,
            'titre': result['title'],
            'url': result['url'],
            'url_part': url_part,
            'file_name': result['file_name'],
            'ann√©e': result['year'],
            'date': result['date'],
            'extrait': result['extract'],
            'type': doc_type,
            'l√©gislature': legislature,
            'p√©riode': periode
        })
    
    return formatted_results

def extract_context(extrait, keyword="BUMIDOM"):
    """Extrait le contexte autour du mot-cl√©"""
    if not extrait:
        return ""
    
    # Trouver la position du mot-cl√©
    texte_lower = extrait.lower()
    keyword_lower = keyword.lower()
    
    pos = texte_lower.find(keyword_lower)
    if pos == -1:
        return extrait[:150] + "..." if len(extrait) > 150 else extrait
    
    # Extraire 100 caract√®res avant et apr√®s
    start = max(0, pos - 100)
    end = min(len(extrait), pos + len(keyword) + 100)
    
    context = extrait[start:end]
    
    # Ajouter des ellipses si n√©cessaire
    if start > 0:
        context = "..." + context
    if end < len(extrait):
        context = context + "..."
    
    return context

def test_url_access(url):
    """Teste l'accessibilit√© d'une URL"""
    try:
        response = requests.head(url, timeout=10, allow_redirects=True)
        return {
            'status_code': response.status_code,
            'content_type': response.headers.get('content-type', ''),
            'accessible': response.status_code == 200
        }
    except Exception as e:
        return {
            'status_code': 0,
            'content_type': '',
            'accessible': False,
            'error': str(e)
        }

def main():
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Analyse des r√©sultats")
        
        keyword = st.text_input("Mot-cl√© analys√©:", value="BUMIDOM")
        
        st.markdown("### üìä Filtres")
        
        show_all = st.checkbox("Afficher tous les r√©sultats", value=True)
        
        if show_all:
            min_year = st.slider("Ann√©e minimum:", 1960, 1990, 1966)
            max_year = st.slider("Ann√©e maximum:", 1960, 1990, 1986)
        
        st.markdown("### üèõÔ∏è Filtres par type")
        doc_types = st.multiselect(
            "Types de documents:",
            ["Tous", "CRI", "Constitution", "Journal Officiel", "Compte Rendu", "D√©bat parlementaire"],
            default=["Tous"]
        )
        
        st.markdown("### üìÖ Filtres par l√©gislature")
        legislatures = st.multiselect(
            "L√©gislatures:",
            ["Toutes", "2√®me", "4√®me", "5√®me", "7√®me", "8√®me"],
            default=["Toutes"]
        )
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        with col1:
            analyze_btn = st.button("üîç Analyser r√©sultats", type="primary", use_container_width=True)
        with col2:
            export_btn = st.button("üì• Exporter donn√©es", use_container_width=True)
        
        st.markdown("---")
        st.info("""
        **Source:** Archives de l'Assembl√©e Nationale
        **P√©riode:** 1966-1986
        **Documents:** 10 r√©sultats trouv√©s
        **Format:** Documents PDF
        """)
    
    # Analyse des r√©sultats
    if analyze_btn or 'results' not in st.session_state:
        with st.spinner("Analyse des r√©sultats Google..."):
            results = parse_google_results()
            st.session_state.results = results
    
    # Affichage des r√©sultats
    if 'results' in st.session_state:
        results = st.session_state.results
        
        st.success(f"‚úÖ {len(results)} documents trouv√©s dans les Archives de l'Assembl√©e Nationale")
        
        # Statistiques
        st.subheader("üìà Statistiques")
        
        col_stat1, col_stat2, col_stat3, col_stat4, col_stat5 = st.columns(5)
        with col_stat1:
            st.metric("Documents", len(results))
        with col_stat2:
            years = len(set(r['ann√©e'] for r in results if r['ann√©e'] != 'N/A'))
            st.metric("Ann√©es", years)
        with col_stat3:
            types = len(set(r['type'] for r in results))
            st.metric("Types", types)
        with col_stat4:
            legislatures_count = len(set(r['l√©gislature'] for r in results if r['l√©gislature']))
            st.metric("L√©gislatures", legislatures_count)
        with col_stat5:
            mentions = sum(1 for r in results if 'extrait' in r and r['extrait'])
            st.metric("Mentions", mentions)
        
        # Tableau des r√©sultats
        st.subheader("üìã Documents trouv√©s")
        
        # Filtrer les r√©sultats
        filtered_results = results
        
        # Filtrer par ann√©e
        if 'show_all' in locals() and not show_all:
            filtered_results = [r for r in filtered_results 
                              if r['ann√©e'] != 'N/A' 
                              and min_year <= r['ann√©e'] <= max_year]
        
        # Filtrer par type
        if "Tous" not in doc_types and doc_types:
            filtered_results = [r for r in filtered_results if r['type'] in doc_types]
        
        # Filtrer par l√©gislature
        if "Toutes" not in legislatures and legislatures:
            filtered_results = [r for r in filtered_results if r['l√©gislature'] in legislatures]
        
        st.info(f"üìÑ {len(filtered_results)} documents apr√®s filtrage")
        
        # Afficher chaque document
        for doc in filtered_results:
            with st.expander(f"üìÑ {doc['titre'][:80]}... ({doc['ann√©e']}) - L√©gislature {doc['l√©gislature']}"):
                col_doc1, col_doc2 = st.columns([3, 1])
                
                with col_doc1:
                    st.markdown(f"**Type:** {doc['type']}")
                    st.markdown(f"**Ann√©e:** {doc['ann√©e']}")
                    st.markdown(f"**Date:** {doc['date']}")
                    st.markdown(f"**L√©gislature:** {doc['l√©gislature']}")
                    st.markdown(f"**P√©riode:** {doc['p√©riode']}")
                    st.markdown(f"**Fichier:** `{doc['file_name']}`")
                    
                    # Afficher l'URL compl√®te comme lien cliquable
                    st.markdown(f"**URL compl√®te:** [{doc['url']}]({doc['url']})")
                    
                    # Extrait Google
                    if doc['extrait']:
                        st.markdown("**Extrait Google:**")
                        # Mettre en √©vidence le mot-cl√©
                        highlighted = re.sub(
                            r'(' + re.escape(keyword) + ')',
                            r'**\1**',
                            doc['extrait'],
                            flags=re.IGNORECASE
                        )
                        st.markdown(f"> {highlighted}")
                    
                    # Informations suppl√©mentaires
                    st.markdown("**Structure d'URL:**")
                    st.code(doc['url'])
                
                with col_doc2:
                    # Test d'acc√®s
                    st.markdown("**Acc√®s:**")
                    
                    if st.button("üîó Tester l'acc√®s", key=f"test_{doc['id']}"):
                        access_info = test_url_access(doc['url'])
                        
                        if access_info['accessible']:
                            st.success(f"‚úÖ Accessible ({access_info['status_code']})")
                            
                            # V√©rifier si c'est un PDF
                            if 'pdf' in access_info['content_type'].lower():
                                st.info("üìÑ Fichier PDF d√©tect√©")
                                
                                # Option de t√©l√©chargement
                                try:
                                    pdf_response = requests.get(doc['url'], timeout=10)
                                    st.download_button(
                                        label="üì• T√©l√©charger PDF",
                                        data=pdf_response.content,
                                        file_name=f"{doc['file_name']}",
                                        mime="application/pdf",
                                        key=f"dl_{doc['id']}"
                                    )
                                except Exception as e:
                                    st.error(f"‚ùå Erreur de t√©l√©chargement: {str(e)[:50]}")
                            else:
                                st.warning(f"‚ö†Ô∏è Type: {access_info['content_type']}")
                        else:
                            if 'error' in access_info:
                                st.error(f"‚ùå Erreur: {access_info['error'][:50]}")
                            else:
                                st.error(f"‚ùå Erreur {access_info['status_code']}")
        
        # Analyses visuelles
        col_anal1, col_anal2 = st.columns(2)
        
        with col_anal1:
            # Analyse par ann√©e
            st.subheader("üìÖ R√©partition par ann√©e")
            
            year_data = {}
            for doc in results:
                if doc['ann√©e'] != 'N/A':
                    year = doc['ann√©e']
                    if year not in year_data:
                        year_data[year] = 0
                    year_data[year] += 1
            
            if year_data:
                df_years = pd.DataFrame({
                    'Ann√©e': list(year_data.keys()),
                    'Documents': list(year_data.values())
                }).sort_values('Ann√©e')
                
                st.bar_chart(df_years.set_index('Ann√©e'))
        
        with col_anal2:
            # Analyse par l√©gislature
            st.subheader("üèõÔ∏è R√©partition par l√©gislature")
            
            legislature_data = {}
            for doc in results:
                if doc['l√©gislature']:
                    leg = doc['l√©gislature']
                    if leg not in legislature_data:
                        legislature_data[leg] = 0
                    legislature_data[leg] += 1
            
            if legislature_data:
                # Trier par ordre num√©rique
                leg_df = pd.DataFrame({
                    'L√©gislature': list(legislature_data.keys()),
                    'Documents': list(legislature_data.values())
                })
                
                # Extraire le num√©ro pour trier
                leg_df['Num'] = leg_df['L√©gislature'].str.extract(r'(\d+)').astype(int)
                leg_df = leg_df.sort_values('Num')
                
                st.bar_chart(leg_df.set_index('L√©gislature')['Documents'])
        
        # Table des URLs
        st.subheader("üîó URLs trouv√©es")
        
        urls_table = pd.DataFrame([{
            'ID': doc['id'],
            'Ann√©e': doc['ann√©e'],
            'L√©gislature': doc['l√©gislature'],
            'Type': doc['type'],
            'Fichier': doc['file_name'],
            'URL': doc['url']
        } for doc in results])
        
        st.dataframe(urls_table, use_container_width=True, hide_index=True)
        
        # Export des donn√©es
        if export_btn:
            st.subheader("üíæ Export des donn√©es")
            
            # Donn√©es compl√®tes
            df_complet = pd.DataFrame(results)
            
            col_exp1, col_exp2, col_exp3, col_exp4 = st.columns(4)
            
            with col_exp1:
                # CSV complet
                csv_data = df_complet.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="üìä CSV complet",
                    data=csv_data,
                    file_name=f"bumidom_archives_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
            
            with col_exp2:
                # URLs seulement
                urls_csv = urls_table.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="üîó URLs seulement",
                    data=urls_csv,
                    file_name=f"bumidom_urls_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
            
            with col_exp3:
                # Rapport textuel
                rapport = f"""
                RAPPORT D'ANALYSE BUMIDOM - ARCHIVES ASSEMBL√âE NATIONALE
                ==========================================================
                
                Date d'analyse: {datetime.now().strftime('%Y-%m-%d %H:%M')}
                Nombre de documents: {len(results)}
                P√©riode couverte: {min(r['ann√©e'] for r in results if r['ann√©e'] != 'N/A')}-{max(r['ann√©e'] for r in results if r['ann√©e'] != 'N/A')}
                
                DOCUMENTS TROUV√âS:
                ------------------
                
                """
                
                for doc in results:
                    rapport += f"""
                {doc['id']}. {doc['titre']}
                   Ann√©e: {doc['ann√©e']}
                   L√©gislature: {doc['l√©gislature']}
                   Type: {doc['type']}
                   Fichier: {doc['file_name']}
                   URL: {doc['url']}
                   Extrait: {doc['extrait'][:150]}...
                   
                """
                
                st.download_button(
                    label="üìù Rapport texte",
                    data=rapport,
                    file_name=f"rapport_bumidom_{datetime.now().strftime('%Y%m%d')}.txt",
                    mime="text/plain"
                )
            
            with col_exp4:
                # Liste des URLs pour navigateur
                urls_list = "\n".join([doc['url'] for doc in results])
                st.download_button(
                    label="üåê URLs pour navigateur",
                    data=urls_list,
                    file_name=f"bumidom_urls_list_{datetime.now().strftime('%Y%m%d')}.txt",
                    mime="text/plain"
                )
    
    else:
        # √âcran d'accueil
        st.markdown("""
        ## üéØ Analyse des Archives BUMIDOM - Assembl√©e Nationale
        
        ### üìö Informations disponibles:
        
        Les documents suivants ont √©t√© identifi√©s dans les archives de l'Assembl√©e Nationale:
        
        1. **Documents PDF** accessibles directement
        2. **Informations structur√©es** : titre, date, l√©gislature, type
        3. **Extraits de texte** contenant "BUMIDOM"
        4. **URLs compl√®tes** pour acc√®s direct
        
        ### üöÄ Fonctionnalit√©s:
        
        - **Analyse automatique** des r√©sultats
        - **Test d'accessibilit√©** des documents PDF
        - **T√©l√©chargement direct** des fichiers
        - **Filtrage avanc√©** par ann√©e, type, l√©gislature
        - **Export des donn√©es** en multiples formats
        
        ### üìã Exemple d'information historique:
        
        ```
        "le BUMIDOM qui, en 1965, a facilit√© l'installation en m√©tropole."
        ```
        
        Cette phrase provient du document **1966-1967-ordinaire1/021.pdf** et t√©moigne du r√¥le historique du BUMIDOM.
        
        ### ‚è±Ô∏è Cliquez sur "üîç Analyser r√©sultats" pour commencer
        """)

if __name__ == "__main__":
    main()
