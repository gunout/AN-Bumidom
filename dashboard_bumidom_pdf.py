import streamlit as st
import pandas as pd
import re
from datetime import datetime
import base64
import io

# Configuration
st.set_page_config(
    page_title="Analyse BUMIDOM - R√©sultats Google", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üìä Analyse des R√©sultats Google BUMIDOM")
st.markdown("Extraction et analyse des informations depuis vos r√©sultats Google")

def parse_google_results():
    """Parse vos r√©sultats Google affich√©s"""
    
    # Vos r√©sultats Google (coll√©s depuis votre message)
    google_results_text = """
    JOURNAL OFFICIAL - Assembl√©e nationale - Archives
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1971-1972-ordinaire1
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    26 oct. 1971 ... Bumidom. Nous avons donc fait un effort tr√®s s√©rieux ‚Äî je crois qu'il commence √† porter ses fruits ‚Äî pour l'information, comme on l'a ...
    
    CONSTITUTION DU 4 OCTOBRE 1958 4' L√©gislature
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1968-1969-ordinaire1
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    9 nov. 2025 ... Bumidom. D√®s mon arriv√©e au minist√®re, je me suis essentielle- ment pr√©occup√© des conditions d'accueil et d'adaptation des originaires des ...
    
    Assembl√©e nationale - Archives
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1966-1967-ordinaire1
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    le BUMIDOM qui, en 1965, a facilit√© l'installation en m√©tropole. La r√©alisation effective de la parit√© globale se poursuivra de 7.000 personnes. en. 1967 . C ...
    
    CONSTITUTION DU 4 OCTOBRE 1958 7' L√©gislature
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1982-1983-ordinaire1
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    5 nov. 1982 ... Le Bumidom, tant d√©cri√© par vos amis, a √©t√©, dans la pratique, remplac√© par un succ√©dan√© ‚Äî l'agence nationale pour l'insertion et la ...
    
    COMPTE RENDU INTEGRAL - Assembl√©e nationale - Archives
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1976-1977-ordinaire2
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    27 janv. 2025 ... des cr√©dits affect√©s au Bumidom pour les ann√©es 1976 et 1977;. 2¬∞ les raisons de la r√©duction des cr√©dits pour l'ann√©e 1977 si tou- tefois ...
    
    CONSTITUTION DU 4 OCTOBRE 1958 4¬∞ L√©gislature
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1970-1971-ordinaire1
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    16 nov. 1970 ... des d√©partements d'outre-mer ‚Äî Bumidom ‚Äî dont l'objectif est √† la fois de faciliter l'immigration et d'orienter les tra- vailleurs vers un ...
    
    JOUR AL OFFICIEL - Assembl√©e nationale - Archives
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1971-1972-ordinaire1
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    5 nov. 2025 ... soci√©t√© d 'Etat ¬´ Bumidom ¬ª, qui prend √† sa charge les frais du voyage. En cons√©quence, il lui demande quelles mesures il compte prendre ...
    
    CONSTITUTION DU 4 OCTOBRE 1958 4¬∞ L√©gislature
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1970-1971-ordinaire1
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    26 oct. 1970 ... Le Bumidom ne devrait pas √™tre trait√© comme un instrument de la ... t√©s d'accueil et du Bumidom, c'est-√†-dire du bureau des migrations.
    
    DE LA R√âPUBLIQUE FRAN√áAISE - Assembl√©e nationale - Archives
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1985-1986-extraordinaire1
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    11 juil. 1986 ... Bumidom . On cr√©e l ' A.N.T., Agence nationale pour l ' inser- tion et la promotion des travailleurs. Le slogan gouverne- mental √©tait ...
    
    JOUR: AL OFFICIEL - Assembl√©e nationale - Archives
    archives.assemblee-nationale.fr ‚Ä∫ cri ‚Ä∫ 1970-1971-ordinaire2
    Image miniature
    Format de fichier : PDF/Adobe Acrobat
    7 mars 2025 ... nis√©e par le Bumidom, est loin d'√™tre satisfaisante. Ses effets sont du reste annihil√©s par l'entr√©e d'une main-d'oeuvre impor- tante dans ...
    """
    
    # Analyser le texte
    lines = google_results_text.strip().split('\n')
    results = []
    current_result = {}
    
    for line in lines:
        line = line.strip()
        
        # Nouveau r√©sultat commence par un titre
        if line and not line.startswith('archives.assemblee-nationale.fr') and not line.startswith('Image') and not line.startswith('Format'):
            if current_result:
                results.append(current_result)
                current_result = {}
            
            if line and len(line) > 10:
                current_result['title'] = line
        
        # URL trouv√©e
        elif 'archives.assemblee-nationale.fr' in line:
            # Extraire l'URL partielle
            match = re.search(r'‚Ä∫ cri ‚Ä∫ (.+)$', line)
            if match:
                url_part = match.group(1).strip()
                current_result['url_part'] = url_part
                
                # Extraire l'ann√©e
                year_match = re.search(r'(\d{4})-(\d{4})', url_part)
                if year_match:
                    current_result['year_start'] = int(year_match.group(1))
                    current_result['year_end'] = int(year_match.group(2))
                    current_result['year'] = int(year_match.group(1))
        
        # Date trouv√©e
        elif re.search(r'\d{1,2}\s+\w+\.?\s+\d{4}', line):
            date_match = re.search(r'(\d{1,2}\s+\w+\.?\s+\d{4})', line)
            if date_match:
                current_result['date'] = date_match.group(1)
        
        # Extrait de texte
        elif 'Bumidom' in line or 'BUMIDOM' in line:
            if 'extract' not in current_result:
                current_result['extract'] = line
            else:
                current_result['extract'] += " " + line
    
    # Ajouter le dernier r√©sultat
    if current_result:
        results.append(current_result)
    
    # Nettoyer et formater les r√©sultats
    formatted_results = []
    for i, result in enumerate(results):
        if 'title' in result and 'url_part' in result:
            # Construire l'URL compl√®te
            url = f"https://archives.assemblee-nationale.fr/cri/{result['url_part']}"
            
            # Identifier le type de document
            doc_type = "CRI"
            if 'CONSTITUTION' in result.get('title', ''):
                doc_type = "Constitution"
            elif 'JOURNAL' in result.get('title', ''):
                doc_type = "Journal Officiel"
            elif 'COMPTE RENDU' in result.get('title', ''):
                doc_type = "Compte Rendu"
            
            formatted_results.append({
                'id': i + 1,
                'titre': result.get('title', 'Document sans titre'),
                'url': url,
                'url_part': result.get('url_part', ''),
                'ann√©e': result.get('year', 'N/A'),
                'date': result.get('date', 'Date inconnue'),
                'extrait': result.get('extract', 'Pas d\'extrait'),
                'type': doc_type,
                'l√©gislature': result.get('year', '')  # Approximation
            })
    
    return formatted_results

def extract_context(extrait, keyword="BUMIDOM"):
    """Extrait le contexte autour du mot-cl√©"""
    if not extrait:
        return ""
    
    # Trouver la position du mot-cl√©
    texte_lower = extrait.lower()
    keyword_lower = keyword.lower()
    
    pos = texte_lower.find(keyword_lower)
    if pos == -1:
        return extrait[:150] + "..." if len(extrait) > 150 else extrait
    
    # Extraire 100 caract√®res avant et apr√®s
    start = max(0, pos - 100)
    end = min(len(extrait), pos + len(keyword) + 100)
    
    context = extrait[start:end]
    
    # Ajouter des ellipses si n√©cessaire
    if start > 0:
        context = "..." + context
    if end < len(extrait):
        context = context + "..."
    
    return context

def main():
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Analyse des r√©sultats")
        
        keyword = st.text_input("Mot-cl√© analys√©:", value="BUMIDOM")
        
        st.markdown("### üìä Filtres")
        
        show_all = st.checkbox("Afficher tous les r√©sultats", value=True)
        
        if show_all:
            min_year = st.slider("Ann√©e minimum:", 1960, 1990, 1966)
            max_year = st.slider("Ann√©e maximum:", 1960, 1990, 1986)
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        with col1:
            analyze_btn = st.button("üîç Analyser r√©sultats", type="primary", use_container_width=True)
        with col2:
            export_btn = st.button("üì• Exporter donn√©es", use_container_width=True)
        
        st.markdown("---")
        st.info("""
        **Source:** R√©sultats Google
        **P√©riode:** 1966-1986
        **Documents:** 10 r√©sultats trouv√©s
        """)
    
    # Analyse des r√©sultats
    if analyze_btn or 'results' not in st.session_state:
        with st.spinner("Analyse des r√©sultats Google..."):
            results = parse_google_results()
            st.session_state.results = results
    
    # Affichage des r√©sultats
    if 'results' in st.session_state:
        results = st.session_state.results
        
        st.success(f"‚úÖ {len(results)} documents trouv√©s dans les r√©sultats Google")
        
        # Statistiques
        st.subheader("üìà Statistiques")
        
        col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
        with col_stat1:
            st.metric("Documents", len(results))
        with col_stat2:
            years = len(set(r['ann√©e'] for r in results if r['ann√©e'] != 'N/A'))
            st.metric("Ann√©es", years)
        with col_stat3:
            types = len(set(r['type'] for r in results))
            st.metric("Types", types)
        with col_stat4:
            mentions = sum(1 for r in results if 'extrait' in r and r['extrait'])
            st.metric("Mentions", mentions)
        
        # Tableau des r√©sultats
        st.subheader("üìã Documents trouv√©s")
        
        # Filtrer par ann√©e si demand√©
        filtered_results = results
        if 'show_all' in locals() and not show_all:
            filtered_results = [r for r in results 
                              if r['ann√©e'] != 'N/A' 
                              and min_year <= r['ann√©e'] <= max_year]
        
        # Afficher chaque document
        for doc in filtered_results:
            with st.expander(f"üìÑ {doc['titre'][:80]}... ({doc['ann√©e']})"):
                col_doc1, col_doc2 = st.columns([3, 1])
                
                with col_doc1:
                    st.markdown(f"**Type:** {doc['type']}")
                    st.markdown(f"**Ann√©e:** {doc['ann√©e']}")
                    st.markdown(f"**Date:** {doc['date']}")
                    st.markdown(f"**URL Google:** `{doc['url_part']}`")
                    
                    # Contexte extrait
                    if doc['extrait']:
                        st.markdown("**Extrait Google:**")
                        
                        # Mettre en √©vidence le mot-cl√©
                        highlighted = re.sub(
                            r'(' + re.escape(keyword) + ')',
                            r'**\1**',
                            doc['extrait'],
                            flags=re.IGNORECASE
                        )
                        st.markdown(f"> {highlighted}")
                    
                    # Informations suppl√©mentaires
                    st.markdown("**Structure d'URL:**")
                    st.code(f"https://archives.assemblee-nationale.fr/cri/{doc['url_part']}")
                
                with col_doc2:
                    # Tentative d'acc√®s
                    st.markdown("**Acc√®s:**")
                    
                    # Bouton pour essayer l'URL
                    if st.button("üîó Tester l'URL", key=f"test_{doc['id']}"):
                        import requests
                        try:
                            response = requests.get(doc['url'], timeout=10)
                            if response.status_code == 200:
                                st.success(f"‚úÖ Accessible ({response.status_code})")
                                
                                # V√©rifier si c'est un PDF
                                if 'pdf' in response.headers.get('content-type', '').lower():
                                    st.info("üìÑ Fichier PDF d√©tect√©")
                                    
                                    # Option de t√©l√©chargement
                                    st.download_button(
                                        label="üì• T√©l√©charger",
                                        data=response.content,
                                        file_name=f"{doc['url_part']}.pdf",
                                        mime="application/pdf",
                                        key=f"dl_{doc['id']}"
                                    )
                                else:
                                    st.warning("‚ö†Ô∏è Pas un PDF")
                            else:
                                st.error(f"‚ùå Erreur {response.status_code}")
                        except Exception as e:
                            st.error(f"‚ùå Erreur: {str(e)[:50]}")
        
        # Analyse par ann√©e
        st.subheader("üìÖ R√©partition par ann√©e")
        
        # Grouper par ann√©e
        year_data = {}
        for doc in results:
            if doc['ann√©e'] != 'N/A':
                year = doc['ann√©e']
                if year not in year_data:
                    year_data[year] = 0
                year_data[year] += 1
        
        if year_data:
            df_years = pd.DataFrame({
                'Ann√©e': list(year_data.keys()),
                'Documents': list(year_data.values())
            }).sort_values('Ann√©e')
            
            # Graphique simple
            st.bar_chart(df_years.set_index('Ann√©e'))
        
        # Table des URLs
        st.subheader("üîó URLs trouv√©es")
        
        urls_table = pd.DataFrame([{
            'ID': doc['id'],
            'Ann√©e': doc['ann√©e'],
            'URL Partielle': doc['url_part'],
            'Type': doc['type']
        } for doc in results])
        
        st.dataframe(urls_table, use_container_width=True)
        
        # Export des donn√©es
        if export_btn:
            st.subheader("üíæ Export des donn√©es")
            
            # Donn√©es compl√®tes
            df_complet = pd.DataFrame(results)
            
            col_exp1, col_exp2, col_exp3 = st.columns(3)
            
            with col_exp1:
                # CSV
                csv_data = df_complet.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="üìä CSV complet",
                    data=csv_data,
                    file_name=f"bumidom_google_results_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
            
            with col_exp2:
                # URLs seulement
                urls_csv = urls_table.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="üîó URLs seulement",
                    data=urls_csv,
                    file_name=f"bumidom_urls_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
            
            with col_exp3:
                # Rapport textuel
                rapport = f"""
                RAPPORT D'ANALYSE BUMIDOM - R√âSULTATS GOOGLE
                ============================================
                
                Date d'analyse: {datetime.now().strftime('%Y-%m-%d %H:%M')}
                Nombre de documents: {len(results)}
                P√©riode couverte: {min(r['ann√©e'] for r in results if r['ann√©e'] != 'N/A')}-{max(r['ann√©e'] for r in results if r['ann√©e'] != 'N/A')}
                
                DOCUMENTS TROUV√âS:
                ------------------
                
                """
                
                for doc in results:
                    rapport += f"""
                {doc['id']}. {doc['titre']}
                   Ann√©e: {doc['ann√©e']}
                   Type: {doc['type']}
                   URL: https://archives.assemblee-nationale.fr/cri/{doc['url_part']}
                   Extrait: {doc['extrait'][:150]}...
                   
                """
                
                st.download_button(
                    label="üìù Rapport texte",
                    data=rapport,
                    file_name=f"rapport_bumidom_{datetime.now().strftime('%Y%m%d')}.txt",
                    mime="text/plain"
                )
    
    else:
        # √âcran d'accueil
        st.markdown("""
        ## üéØ Analyse des R√©sultats Google BUMIDOM
        
        ### Probl√®me identifi√©:
        Les URLs trouv√©es dans Google retournent **404** quand on essaie d'y acc√©der directement.
        
        ### Solution:
        Analyser les **extraits de texte** que Google a d√©j√† index√©s, qui contiennent les informations pr√©cieuses.
        
        ### üìä Informations disponibles dans vos r√©sultats:
        
        1. **Titres des documents**
        2. **URLs structurelles** (pattern)
        3. **Dates de publication**
        4. **Extraits de texte** contenant "BUMIDOM"
        5. **Types de documents** (CRI, Journal Officiel, etc.)
        
        ### üöÄ Ce que fait cette analyse:
        
        - **Extrait automatiquement** les informations de vos r√©sultats Google
        - **Analyse le contexte** autour de "BUMIDOM"
        - **Organise par ann√©e** et type de document
        - **G√©n√®re un rapport** d√©taill√©
        - **Permet de tester** les URLs une par une
        
        ### üìã Exemple d'extrait analys√©:
        
        ```
        "le BUMIDOM qui, en 1965, a facilit√© l'installation en m√©tropole."
        ```
        
        Cette phrase vient du document **1966-1967-ordinaire1** et contient d√©j√† une information historique pr√©cieuse.
        
        ### ‚è±Ô∏è Cliquez sur "üîç Analyser r√©sultats" pour commencer
        """)

if __name__ == "__main__":
    main()
